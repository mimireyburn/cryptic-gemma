{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q -U bitsandbytes==0.42.0\n",
    "!pip3 install -q -U peft==0.8.2\n",
    "!pip3 install -q -U trl==0.7.10\n",
    "!pip3 install -q -U accelerate==0.27.1\n",
    "!pip3 install -q -U datasets==2.17.0\n",
    "!pip3 install -q -U transformers==4.38.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GemmaTokenizer\n",
    "\n",
    "model_id = \"google/gemma-7b\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=os.environ['HF_TOKEN'])\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0}, token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Given the following cryptic clue for a cryptic crossword, what is the answer?\\n\\nClue:\\nPointed shoe parts with circular fitments.\\n\\nAnswer:\\n\"\n",
    "device = \"cuda:0\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# data = load_dataset(\"Abirate/english_quotes\")\n",
    "# data = data.map(lambda samples: tokenizer(samples[\"quote\"]), batched=True)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "TEMPLATE = \"Given the following cryptic clue for a cryptic crossword, what is the answer?\\nClue:\\n{title}\\n\\nAnswer:\\n{content}\"\n",
    "\n",
    "class CrypticDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('google/gemma-7b', token=os.environ['HF_TOKEN'])\n",
    "        \n",
    "        self.data = pd.read_csv(csv_file, header=None)\n",
    "        \n",
    "        self.ds = self.data.apply(self.prompt, axis=1)\n",
    "        self.ds = self.ds.apply(self.tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx]\n",
    "\n",
    "    def prompt(self, col):\n",
    "        return TEMPLATE.format(title=col[1], content=col[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from torch.utils.data import Dataset, random_split, Subset\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a torch.Generator object\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(42)\n",
    "\n",
    "dataset = CrypticDataset(\"uk_cryptics.csv\")\n",
    "\n",
    "# Shuffle the indices of the dataset\n",
    "indices = torch.randperm(len(dataset))\n",
    "\n",
    "# Select the first 1500 elements\n",
    "subset_indices = indices[:1500]\n",
    "\n",
    "# Create a Subset of the dataset using the selected indices\n",
    "subset_dataset = Subset(dataset, subset_indices)\n",
    "\n",
    "# Assuming you have a sampled dataset called 'shuffled_dataset'\n",
    "train_size = int(0.6 * len(subset_dataset))\n",
    "val_size = int(0.2 * len(subset_dataset))\n",
    "test_size = len(subset_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(subset_dataset, [train_size, val_size, test_size], generator=generator)\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "print(\"Example training sample:\", dataset.ds[151])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example training sample:\", dataset.ds[152])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=2,\n",
    "        max_steps=10,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        save_steps=200,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\"\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    ")\n",
    "trainer.train()\n",
    "model.save_pretrained(\"./weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Given the following cryptic clue for a cryptic crossword, what is the answer?\\n\\nClue:\\nPointed shoe parts with circular fitments.\\n\\nAnswer:\\n\"\n",
    "device = \"cuda:0\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
